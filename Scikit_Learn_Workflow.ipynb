{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import seaborn as sns\n",
    "matplotlib.rcParams['savefig.dpi'] = 2 * matplotlib.rcParams['savefig.dpi']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Goals\n",
    "===========\n",
    " - Understand how to write custom classes in scikit-learn\n",
    " - Pipelines\n",
    " - Feature Unions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Custom Estimators and Transformers\n",
    "===========\n",
    "\n",
    "The scikit-learn library has a wealth of functionality available in its [classes](http://scikit-learn.org/stable/modules/classes.html). Occasionally you might want to customize the behavior of these classes, for example to add in functionality or for engineering reasons.\n",
    "\n",
    "All estimators (e.g. linear regression, kmeans, etc ...) support `fit` and `predict` methods.  In fact, you can build your own by inheriting from classes in `sklearn.base` by using this template:                                                                                                 \n",
    "``` python                                                                                                                                        \n",
    "class Estimator(base.BaseEstimator, base.RegressorMixin):\n",
    "  def __init__(self, ...):\n",
    "  # initialization code\n",
    "  \n",
    "  def fit(self, X, y):\n",
    "  # fit the model ...\n",
    "    return self\n",
    "    \n",
    "  def predict(self, X):\n",
    "    return # prediction\n",
    "    \n",
    "  def score(self, X, y):\n",
    "    return # custom score implementation\n",
    "```\n",
    "\n",
    "Conforming to this convention has the benefit that many tools (e.g. cross-validation, grid search) rely on this interface so you can use your new estimators with the existing `sklearn` infrastructure.                                                                 \n",
    "                                                                                \n",
    "For example `grid_search.GridSearchCV` ([docs](http://scikit-learn.org/stable/modules/generated/sklearn.grid_search.GridSearchCV.html)) takes an estimator and some hyperparameters as arguments, and returns another estimator.  Upon fitting, it fits the best model (based on the inputted hyperparameters) and uses that for prediction.                                                                    \n",
    "                                                                                \n",
    "Of course, we sometimes need to process or transform the data before we can do machine-learning on it.  `sklearn` has Transformers to help with this.  They implement this interface:\n",
    "``` python\n",
    "class Transformer(base.BaseEstimator, base.TransformerMixin):\n",
    "  def __init__(self, ...):\n",
    "    # initialization code\n",
    "    \n",
    "  def fit(self, X, y=None):\n",
    "    # fit the transformation\n",
    "    return self\n",
    "  \n",
    "  def transform(self, X):\n",
    "    return ... # transformation\n",
    "```\n",
    "\n",
    "A comprehensive `.fit_transform` is implemented based on the `.fit` and `.transform` methods in `base.TransformerMixin` ([docs](http://scikit-learn.org/stable/modules/generated/sklearn.base.TransformerMixin.html)). However, especially for transformers, `.fit` is often empty and only `.transform` actually does something.\n",
    "\n",
    "The following is some example code to demonstrate the usage of custom classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "import sklearn as sk\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.datasets import load_boston\n",
    "\n",
    "boston = load_boston()\n",
    "X_train, X_test, y_train, y_test = train_test_split(boston.data, boston.target, test_size=0.2, random_state=42)\n",
    "\n",
    "class TruncateTransformer(sk.base.BaseEstimator, sk.base.TransformerMixin):\n",
    "    \"\"\"\n",
    "    Returns the first k columns of a feature array\n",
    "    \"\"\"\n",
    "    def __init__(self, k):\n",
    "        self.k = k\n",
    "        pass\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return X[:,:self.k]\n",
    "\n",
    "\n",
    "class ShellEstimator(sk.base.BaseEstimator, sk.base.RegressorMixin):\n",
    "    \"\"\"\n",
    "    A shell estimator that only takes prefit models and premade transformers.\n",
    "    Its sole function is to combine a transformer and regressor into a single object.\n",
    "    \"\"\"\n",
    "    def __init__(self, transformer, model):\n",
    "        self.transformer = transformer\n",
    "        self.model = model\n",
    "        pass\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        return self\n",
    "    \n",
    "    def score(self, X, y):\n",
    "        X_test = self.transformer.transform(X)\n",
    "        return self.model.score(X_test, y)\n",
    "\n",
    "    def predict(self, X):\n",
    "        X_test = self.transformer.transform(X)\n",
    "        return self.model.predict(X_test)\n",
    "\n",
    "linreg = LinearRegression(fit_intercept=True)\n",
    "model = linreg.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "print model.score(X_test, y_test)\n",
    "    \n",
    "truncator = TruncateTransformer(2)\n",
    "X_train_k = truncator.transform(X_train)\n",
    "X_test_k = truncator.transform(X_test)\n",
    "\n",
    "k_model = linreg.fit(X_train_k, y_train)\n",
    "y_pred_k = k_model.predict(X_test_k)\n",
    "print k_model.score(X_test_k, y_test)\n",
    "\n",
    "k_shell = ShellEstimator(truncator, k_model)\n",
    "assert(k_shell.predict(X_test_k).all() == y_pred_k.all())\n",
    "print k_shell.score(X_test_k, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pipelines\n",
    "===========\n",
    "\n",
    "It turns out there's a built-in tool to chain together our transformers and estimators into one unit, and it scales much easier than custom estimators. They're called pipelines. The following code would replace all the fitting and scoring code above.  That is, the pipeline itself is an estimator (and implements the `.fit` and `.predict` methods).  Note that a pipeline can have multiple transformers chained up but at most one (optional) terminal estimator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import pipeline\n",
    "\n",
    "k_pipe = pipeline.Pipeline([\n",
    "  ('truncate', TruncateTransformer(2)),\n",
    "  ('linreg', LinearRegression(fit_intercept=True))\n",
    "  ])\n",
    "k_pipe.fit(X_train, y_train)\n",
    "print k_pipe.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Unions\n",
    "===========\n",
    "\n",
    "[Feature unions](http://scikit-learn.org/stable/modules/generated/sklearn.pipeline.FeatureUnion.html) are designed to get around the problem that you might not be able to prepare your desired feature matrix with just one series of transformations. For example, you might have text features, categorical features, and a couple different kinds of numerical features and want feed them all into the same estimator or pipeline. Each feature type would require a different kind of transformer.\n",
    "\n",
    "What the feature union does is a kind of *parallel* transformation operation using multiple transformers and consolidating them into one output matrix - which can then be fed into an estimator or pipeline. You can imagine that between the serial behavior of pipelines and the parallel behavior of feature unions you can create complex multi-stage workflows.\n",
    "\n",
    "This example code applies several different transformations to X before throwing the features into a Linear Regressor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class ReverseTruncateTransformer(sk.base.BaseEstimator, sk.base.TransformerMixin):\n",
    "    \"\"\"\n",
    "    Returns the last k columns of a feature array\n",
    "    \"\"\"\n",
    "    def __init__(self, k):\n",
    "        self.k = k\n",
    "        pass\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return X[:,-self.k:]\n",
    "     \n",
    "all_features = pipeline.FeatureUnion([\n",
    "  ('first two cols', TruncateTransformer(2)),\n",
    "  ('last two cols', ReverseTruncateTransformer(2))\n",
    "  ])\n",
    "k_union = pipeline.Pipeline([(\"features\", all_features), (\"linreg\", LinearRegression(fit_intercept=True))])\n",
    "k_union.fit(X_train, y_train)\n",
    "print k_union.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also use feature unions to combine the predictions of multiple estimators. If you rewrite your estimators as transformers and feed them into a feature union which has eg. a linear regressor as an estimator, you'll be able to automatically weight and combine each individual prediction into an ensemble model.\n",
    "\n",
    "To do this, you'll need to write custom transformers where the `.transform` method carries out the `.predict` implementation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Copyright &copy; 2015 The Data Incubator.  All rights reserved.*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
