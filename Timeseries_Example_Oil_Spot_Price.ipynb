{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import seaborn as sns\n",
    "matplotlib.rcParams['savefig.dpi'] = 2 * matplotlib.rcParams['savefig.dpi']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model building. \"Timeseries\" case study: Forecasting oil spot price"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Goals / Topics\n",
    " - Trend\n",
    " - Seasonal effects / Fourier transform\n",
    " - Lagged inputs, autocorrelation\n",
    " - Testing with timeseries data\n",
    " - Autoregressive models, VAR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##The problem: Timeseries forecasting\n",
    "\n",
    "Try to predict the daily average _spot price for crude oil_ three months (:=60 market days) out.  For a change, we will also try to predict _hourly temperature data_ (for Pittsburgh) 24 hours out."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**The type of learner**: This is a _supervised regression_ problem.\n",
    "\n",
    "**The training dataset**: We'll get historical oil spot price data from Quandl.  We'll get historical hourly temperate data (the NWS Pittsburgh Climate Data) from NOAA.  Time allowing, we could try throwing in some non-financial signals, namely \"political event\" data from [The Global Database of Events, Language, and Tone (GDELT)](http://gdeltproject.org/)\n",
    "\n",
    "**The test dataset**: We will generate a holdout data set from the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import Quandl\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.linear_model\n",
    "import sklearn.metrics\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# To really use the Quandl API, you should get an authtoken.  Limited usage doesn't require it.\n",
    "\n",
    "authtoken = None\n",
    "# authtoken = \"your token here\"\n",
    "\n",
    "\n",
    "def getQuandl(what):\n",
    "    \"\"\" \n",
    "    Wrapper around Quandl requests, using authtoken only if available\n",
    "    \"\"\"\n",
    "    if authtoken:\n",
    "        return Quandl.get(what, authtoken=authtoken)\n",
    "    else:\n",
    "        return Quandl.get(what)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "oil = getQuandl(\"DOE/RWTC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "oil.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Create a column with \"true\" (future) values\n",
    "PERIOD_MONTH = 20\n",
    "PREDICTION_LAG = 3 * PERIOD_MONTH\n",
    "\n",
    "CUT_YEAR = 2008\n",
    "oil['Actual'] = oil['Value'].shift(-PREDICTION_LAG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First Step: Take out any 'inflationary' effects.\n",
    "Suppose, instead, we'd been asked to predict the value **one year** or **five years** out.  The simplest model that we might try is just exponential growth\n",
    "   $$ P(t) = \\exp\\left( c_0 + c_1 t \\right) $$\n",
    "\n",
    "To train it we just use a linear regression on $\\log P(t)$ to build this model.  If we want to do better, we can content ourselves with modeling its error term."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "oil['Julian'] = oil.index.to_julian_date()\n",
    "oil = sm.add_constant(oil) # Add a constant field for the linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train = oil[oil.index.year < CUT_YEAR].dropna(how='any')\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Some justification is required for not doing in-/out-sample here...\n",
    "#train = oil[ oil.index.year < CUT_YEAR ].dropna(how='any')\n",
    "train = oil\n",
    "exponential_model = sklearn.linear_model.Ridge().fit( \n",
    "    X=train[['Julian', 'const']], \n",
    "    y=np.log(train['Value'])\n",
    ")\n",
    "\n",
    "exp_model_df = oil\n",
    "exp_model_df['Exponential_Model'] = np.exp(exponential_model.predict(oil[['Julian', 'const']]))\n",
    "exp_model_df['Log_Error_Exponential'] = np.log(oil['Value'] / oil['Exponential_Model'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "exp_model_df[['Value', 'Exponential_Model']].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Step 2: Seasonal effects\n",
    "We might guess that the price of oil goes up in the winter and down in the summer.  Of course, oil can be stored and in an efficient futures market this would be priced in -- so we might _not_ expect to see it.  Let's do two analyses to try to check for it:\n",
    " - Visual inspection (with a weighted average, for smoothing)\n",
    " - A Fast Fourier Transform\n",
    " \n",
    "(Later on, we will also look at the _autocorrelation_ which is another technique for this.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weighted average (with smoothing)\n",
    "There are many types of [moving average](http://en.wikipedia.org/wiki/Moving_average).  We will be computing the exponentially weighted moving average:\n",
    "\n",
    "$$E_t = \\alpha X_t + (1-\\alpha)E_{t-1}$$\n",
    "\n",
    "Since we can see that something crazy happened in 2008 (financial meltdown) and something else crazy happened in 1992 (Iraq War), we'll restrict to between those two dates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "log_error = oil['Log_Error_Exponential'][(oil.index.year > 1992) & (oil.index.year < 2008)]\n",
    "pd.DataFrame({\n",
    "    'log_error': log_error,\n",
    "    'ewma': pd.ewma(log_error, span=100)\n",
    "}).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FFT\n",
    "\n",
    "We can also take a **Fourier transform** (more precisely, an FFT).\n",
    "\n",
    "The Fourier transform can be thought of as a representation of all the frequency components of your data. In some sense it is a histogram with each “frequency bin” corresponding to how often a particular frequency occurs in your signal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy import fftpack\n",
    "\n",
    "fft = fftpack.fft(oil['Log_Error_Exponential'][(oil.index.year > 1992) & (oil.index.year < 2010)])\n",
    "plt.plot(np.abs(fft))\n",
    "plt.ylim([0, 700])\n",
    "plt.xlim([0, 400])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**So what?**  There seems to be pretty much no visible season effect..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** Suppose we had use something that _is_ clearly seasonal (e.g., the temperature data in the next cell).  Carry out the above analysis (and the lagged auto-correlation one below) with the temperature data below, and confirm that it is reasonable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!head projects/timeseries-project/data/raw/temperatures.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "temps_df = pd.read_csv(\"projects/timeseries-project/data/raw/temperatures.csv\", \n",
    "                       index_col=0,\n",
    "                       names=[\"Temperature\"],\n",
    "                       parse_dates=True,\n",
    "                       date_parser=lambda u: pd.datetime.strptime(u, \"%Y-%m-%d %H:%M:%S\"))\n",
    "temps_df[:24 * 7].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Your code here ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross validation: In sample and out of sample data sets.\n",
    "\n",
    "In the above, when we built our simple model, we used all of history for training (and if we did any testing, we again used all of history for that).  When building a predictor, we should be doing some cross validation to make sure that we do not overfit.  \n",
    "\n",
    "How do we do cross validation for time series data?  Here are some things we generally cannot do:\n",
    " - We cannot just pick data points at random, because there might be lagged indicators / seasonal effects / etc. that force us to work with contiguous blocks of time.  \n",
    " - We cannot blindly chop by e.g., month or year without some thought: There could be seasonal effects so that Decembers are always different.  There could be systemic \"regime changes\" that mean that cutting at a given date is inappropriate, or known and time-limited effects that last a year (or fraction thereof).   For instance, the years 1991 and 2008 in this data set.\n",
    " - We cannot have our testing set occur before our training set.\n",
    " \n",
    "One common technique is to use a rolling window, sometimes called [forward chaining](http://stats.stackexchange.com/questions/14099/using-k-fold-cross-validation-for-time-series-model-selection).\n",
    "\n",
    "- fold 1 : training [1], test [2]\n",
    "- fold 2 : training [1 2], test [3]\n",
    "- fold 3 : training [1 2 3], test [4]\n",
    "- fold 4 : training [1 2 3 4], test [5]\n",
    "- fold 5 : training [1 2 3 4 5], test [6]\n",
    "\n",
    "For consistency, you often keep the training window size fixed.\n",
    " \n",
    "We will pick the following training and testing sets:\n",
    " - **Train**: years <2008\n",
    " - **Test**: years 2008-present\n",
    " \n",
    "We've picked this to be purposefully a little perverse: it includes the (crazy) price swings of 2008 in the testing set.\n",
    " \n",
    "To start with, we will apply these techniques to a very simple first model:\n",
    "  - A \"benchmark\" model: we will just use the current value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Cross validation -- benchmark model\n",
    "\n",
    "#Train/Test\n",
    "train = oil[(oil.index.year < CUT_YEAR)].copy()\n",
    "test = oil[(oil.index.year >= CUT_YEAR)].copy()\n",
    "\n",
    "# Reporting function\n",
    "def summarize_errors(test_me):\n",
    "    error_pct = ((test_me['Actual'] - test_me['Model'])/test_me['Actual'])\n",
    "\n",
    "    print error_pct.describe()\n",
    "    error_pct.plot()\n",
    "    plt.show()\n",
    "\n",
    "    error_pct.hist(bins=100, normed=True)\n",
    "    x = np.arange(-1, 0.5, 0.001)\n",
    "    n_pdf = sp.stats.norm(loc=error_pct.mean(), scale=error_pct.std()).pdf\n",
    "    plt.plot(x, n_pdf(x), linewidth=3, color='red')\n",
    "    plt.show()\n",
    "\n",
    "    print sklearn.metrics.mean_squared_error(test_me['Actual'], test_me['Model'])\n",
    "\n",
    "test['Benchmark_Model'] = oil['Value']\n",
    "test_me = test[['Actual', 'Benchmark_Model']].dropna(how='any') \\\n",
    "                                             .rename(columns={\"Benchmark_Model\": \"Model\"})\n",
    "summarize_errors(test_me)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Step 3: Lagged auto-correlation\n",
    "For many time series, the best prediction for $t_{i+1}$ is $t_{i}$ or $t_{i-1}$.  We used something similar as our \"benchmark\" model above.\n",
    "\n",
    "One proxy for measuring this is the __auto-correlation__: that is, the correlation between the sequences $t_{i+1}$ and $t_{i}$ (or more generally $t_i$ and $t_{i-\\ell}$ for some lag $\\ell$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pandas.tools.plotting import autocorrelation_plot\n",
    "\n",
    "autocorrelation_plot(oil.Value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### So what?\n",
    "The autocorrelation starts off high, using the last few day's values is likely to be useful.  There are no extra \"bumps\" or peaks, consistent with our observation that there were no seasonal effects.  \n",
    "\n",
    "Let's build a second model -- which we will call the \"simple\" model -- which is also auto-regressive but now takes into account our exponential model from above.  Namely: we will start with the exponential model from before, and then try to estimate __its error__ using an auto-regressive linear model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Cross validation -- simple model\n",
    "\n",
    "#Train/Test\n",
    "train = oil[oil.index.year < CUT_YEAR]\n",
    "test = oil[oil.index.year >= CUT_YEAR]\n",
    "\n",
    "# Reporting function\n",
    "def summarize_errors(test_me):\n",
    "    error_pct = (test_me['Actual'] - test_me['Model']) / test_me['Actual']\n",
    "\n",
    "    print error_pct.describe()\n",
    "    error_pct.plot()\n",
    "    plt.show()\n",
    "\n",
    "    error_pct.hist(bins=100, normed=True)\n",
    "    x = np.arange(-1, 1, 0.001)\n",
    "    plt.plot(x, sp.stats.norm(loc=error_pct.mean(), scale=error_pct.std()).pdf(x), linewidth=3, color='red')\n",
    "    plt.show()\n",
    "\n",
    "    print sklearn.metrics.mean_squared_error( test_me['Actual'], test_me['Model'] )\n",
    "\n",
    "# Train the regression\n",
    "def frame_to_feats(frame):\n",
    "    feats = pd.DataFrame()\n",
    "    \n",
    "    feats['LEE'] = frame['Log_Error_Exponential']\n",
    "    feats['LEE_1'] = frame['Log_Error_Exponential'].shift(1)\n",
    "    feats['dLEE_avg'] = pd.rolling_mean(frame['Value'].diff(), window=3*PERIOD_MONTH)\n",
    "    feats['vol_avg'] = pd.ewmvar(frame['Value'], span=3*PERIOD_MONTH)\n",
    "    \n",
    "    feats['Actual_LEE'] = frame['Log_Error_Exponential'].shift(-PREDICTION_LAG)\n",
    "    return sm.add_constant(feats)\n",
    "\n",
    "feats = frame_to_feats(train).dropna(how='any')\n",
    "regress = sklearn.linear_model.LinearRegression().fit( \n",
    "        X=feats.drop('Actual_LEE', axis=1).values, \n",
    "        y=feats['Actual_LEE'].values)\n",
    "\n",
    "# Predict\n",
    "\n",
    "feats = frame_to_feats(test).dropna(how='any')\n",
    "feats['Predicted_LEE'] = regress.predict(X=feats.drop('Actual_LEE', axis=1))\n",
    "\n",
    "test = feats.join(test, rsuffix='_r').dropna(how='any')\n",
    "test['Simple_Model'] = np.exp(test['Predicted_LEE']) * test['Exponential_Model']\n",
    "\n",
    "# Report\n",
    "test_me = test[['Actual', 'Simple_Model']].dropna(how='any') \\\n",
    "                                          .rename(columns={'Simple_Model': 'Model'})\n",
    "summarize_errors(test_me)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Step 4: Adding external indicators (e.g., volatility, gdelt)\n",
    "\n",
    "Once we have a  \"simplest\"  model as above, we can get to the interesting part:\n",
    "At this point we like to find signal in additional data source that accounts for some of the error; to try to conceptually explain sources of error or skews in the distribution of error; etc.  Here are examples of other data sources we might try:\n",
    "\n",
    "  - Other financial indicators (e.g., interest rates, volatilities, related commodities)\n",
    "  - Non-financial indicators (e.g., weather, indicators for weather patterns / wars, geopolitical data like gdelt).\n",
    "  \n",
    "We'll show the example of trying to use equities volatility data (in the form of the VIX index) -- this will not help."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ng_fut = getQuandl(\"CHRIS/CME_NG1\")\n",
    "vix = getQuandl(\"YAHOO/INDEX_VIX\")\n",
    "\n",
    "oil['vix'] = vix['Adjusted Close']\n",
    "oil['ng_fut'] = ng_fut['Settle']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print oil['Log_Error_Exponential'].corr(oil['vix'])  # Our error term does correlate negatively with vix...\n",
    "print oil['Log_Error_Exponential'].corr(oil['ng_fut'])\n",
    "\n",
    "oil['vix'].plot()\n",
    "plt.show()\n",
    "\n",
    "oil['ng_fut'].plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Cross validation -- complex model -- notice that we have overfit!\n",
    "\n",
    "#Train/Test\n",
    "train = oil[oil.index.year < CUT_YEAR]\n",
    "test = oil[oil.index.year >= CUT_YEAR]\n",
    "\n",
    "# Reporting function\n",
    "def summarize_errors(test_me):\n",
    "    error_pct = (test_me['Actual'] - test_me['Model']) / test_me['Actual']\n",
    "\n",
    "    print error_pct.describe()\n",
    "    error_pct.plot()\n",
    "    plt.show()\n",
    "\n",
    "    error_pct.hist(bins=100, normed=True)\n",
    "    x = np.arange(-0.5, 0.5, 0.001)\n",
    "    n_pdf = sp.stats.norm(loc=error_pct.mean(), scale=error_pct.std()).pdf\n",
    "    plt.plot(x, n_pdf(x), linewidth=3, color='red')\n",
    "    plt.show()\n",
    "\n",
    "    print sklearn.metrics.mean_squared_error( test_me['Actual'], test_me['Model'] )\n",
    "\n",
    "# Train the regression\n",
    "def frame_to_feats(frame):\n",
    "    feats = pd.DataFrame()\n",
    "    \n",
    "    feats['LEE'] = frame['Log_Error_Exponential']\n",
    "    feats['dLEE_avg'] = pd.rolling_mean(frame['Value'].diff(), window=3*PERIOD_MONTH)\n",
    "    feats['vol_avg'] = pd.ewmvar(frame['Value'], span=3*PERIOD_MONTH)\n",
    "    \n",
    "    feats['ng_fut'] = frame['ng_fut']\n",
    "    \n",
    "    feats['Actual_LEE'] = frame['Log_Error_Exponential'].shift(-PREDICTION_LAG)\n",
    "    return sm.add_constant(feats)\n",
    "    \n",
    "\n",
    "feats = frame_to_feats(train).dropna(how='any')\n",
    "regress = sklearn.linear_model.LinearRegression().fit( \n",
    "        X=feats.drop('Actual_LEE', axis=1), \n",
    "        y=feats['Actual_LEE'])\n",
    "\n",
    "# Predict\n",
    "\n",
    "feats = frame_to_feats(test).dropna(how='any')\n",
    "feats['Predicted_LEE'] = regress.predict(feats.drop('Actual_LEE', axis=1))\n",
    "\n",
    "test = feats.join(test, rsuffix='_r').dropna(how='any')\n",
    "test['Complex_Model'] = np.exp (test['Predicted_LEE']) * test['Exponential_Model']\n",
    "\n",
    "# Report\n",
    "test_me = test[['Actual', 'Complex_Model']].dropna(how='any') \\\n",
    "                                           .rename(columns = {'Complex_Model': 'Model'})\n",
    "summarize_errors(test_me)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Open-ended brainstorming / exercises\n",
    "\n",
    "1. What happens to the results above if we change our \"cut point\" to say 2010?  What's the moral of this story...\n",
    "\n",
    "2. Play around with the previous \"Complex\" model, and see if you can improve it.  What happens, for instance, if you get rid of the 'vix' signal.  Why do you think this might be the case?\n",
    "\n",
    "3. What are some other \"simplest\" models we could have tried? e .g., linear regression just on 'Value' rather than going through this log stuff.  Try some of them -- how do they perform?\n",
    "\n",
    "4. Carry out the whole analysis process for the Pittsburgh temperate data (see below for some steps.. if you do use that, mark it up to explain what's happening)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Fancier topic: Stochastic auto-regressive models\n",
    "\n",
    "Our time series has, very cleary, time-varying volatility.  To accurately model these effects, one often uses stochastic models.  To start you Googling, the basic auto-regressive examples are **ARCH/GARCH**.  \n",
    "\n",
    "Let us say just a little about these, leaving an example as an exercise to the reader.  In this type of model, the next time tick's value is drawn from a _distribution_ whose mean **and** standard deviation are modelled over time (and can, in general, be auto-regressive):\n",
    "\n",
    "$$ t_{i+1} = M(\\text{..factors..}) + \\sigma(\\text{..factors..}) \\epsilon_t $$\n",
    "\n",
    "where \n",
    "  - $M$ is some model for the mean (e.g., a linear model depending on some number of time lags of $t_{i}$ and moving averages in GARCH models);\n",
    "  - $\\sigma$ is some model for the standard deviation (as above in GARCH);\n",
    "  - and, $\\epsilon_t$ is a draw from a distribution having (conditional on the factors..) mean equal to zero, and standard deviation equal to one.  (In ARCH, this is a normal distribution.)\n",
    "  \n",
    "Stochastic models allow us to generate a range of future paths, for instance for modelling \"value at risk.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "##ARMA models: Combining auto-regressive and moving average\n",
    "\n",
    "If a time series can be made stationary by differencing or by the methods above, it is common to model them using some combination of autoregressive terms (weighted average over some recent values) and moving average terms (weighted average over some recent errors) of different orders - in Python you can find this functionality in the statsmodels library. The number of terms can be determined through various methods and rules of thumb. [Read more.](http://people.duke.edu/~rnau/411arim.htm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A more positive example: Temperatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "temps_df = pd.read_csv(\"projects/timeseries-project/data/raw/temperatures.csv\", \n",
    "                       index_col=0,\n",
    "                       names=[\"Temperature\"],\n",
    "                       parse_dates=True,\n",
    "                       date_parser=lambda u: pd.datetime.strptime(u, \"%Y-%m-%d %H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ts = temps_df['Temperature'].asfreq('60Min', method='ffill')\n",
    "temps_df['Temperature'] = ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 2-month exponential moving average\n",
    "pd.ewma(ts, span=2*30).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy import fftpack\n",
    "fft = fftpack.fft(ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(np.abs(fft))\n",
    "plt.title(\"FFT of temperature data (zoomed out)\")\n",
    "plt.ylim([0,1000000])\n",
    "plt.xlim([0,10000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(np.abs(fft))\n",
    "plt.title(\"FFT of temperature data (zoomed in)\")\n",
    "plt.ylim([0,1000000])\n",
    "plt.xlim([0,24*2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(np.array([ts.corr(ts.tshift(i)) for i in xrange(1, 24*5)]))\n",
    "plt.title(\"Lagged autocorrelation (over five days)\")\n",
    "plt.ylabel(\"Correlation\")\n",
    "plt.xlabel(\"Lag (hours)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(np.array([ts.corr(ts.tshift(i)) for i in xrange(1, 8766, 24)]))\n",
    "plt.title(\"Lagged autocorrelation (over a year)\")\n",
    "plt.ylabel(\"Correlation\")\n",
    "plt.xlabel(\"Lag (days)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "We can always decompose\n",
    "$$F(t) = k \\cos(\\omega (t - t_0)) = k \\left[\\alpha \\cos(\\omega t) + \\beta \\sin(\\omega t) \\right]$$\n",
    "where $\\alpha^2 + \\beta^2 = 1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "temps_df['Julian'] = temps_df.index.to_julian_date()\n",
    "temps_df['const'] = 1\n",
    "temps_df['sin(year)'] = np.sin(temps_df['Julian'] / 365.25 * 2 * np.pi)\n",
    "temps_df['cos(year)'] = np.cos(temps_df['Julian'] / 365.25 * 2 * np.pi)\n",
    "temps_df['sin(6mo)'] = np.sin(temps_df['Julian'] / (365.25 / 2) * 2 * np.pi)\n",
    "temps_df['cos(6mo)'] = np.cos(temps_df['Julian'] / (365.25 / 2) * 2 * np.pi)\n",
    "temps_df['sin(day)'] = np.sin(temps_df.index.hour / 24.0 * 2* np.pi)\n",
    "temps_df['cos(day)'] = np.cos(temps_df.index.hour / 24.0 * 2* np.pi)\n",
    "temps_df['Day_Average'] = pd.ewma(temps_df['Temperature'], span=24)\n",
    "\n",
    "temps_df['Goal'] = temps_df['Temperature'].shift(-24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cut_year = 2012\n",
    "\n",
    "train = temps_df[ temps_df.index.year < cut_year ].dropna(how='any')\n",
    "test  = temps_df[ temps_df.index.year >= cut_year].dropna(how='any')\n",
    "\n",
    "regress = sklearn.linear_model.LinearRegression().fit( \n",
    "        X=train[['Temperature']], \n",
    "        y=train['Goal'])\n",
    "\n",
    "test['Predicted_Value'] = regress.predict(X=test[['Temperature']])\n",
    "\n",
    "(test['Goal'] - test['Predicted_Value']).plot()\n",
    "print sklearn.metrics.mean_squared_error(test['Goal'], test['Predicted_Value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cut_year = 2012\n",
    "\n",
    "train = temps_df[temps_df.index.year < cut_year].dropna(how='any')\n",
    "test  = temps_df[temps_df.index.year >= cut_year].dropna(how='any')\n",
    "\n",
    "regress = sklearn.linear_model.LinearRegression().fit( \n",
    "        X=train[['Temperature', 'Day_Average', 'sin(year)', 'cos(year)', 'sin(6mo)', 'cos(6mo)', 'sin(day)', 'cos(day)']], \n",
    "        y=train['Goal'])\n",
    "\n",
    "test['Predicted_Value'] = regress.predict(X=test[['Temperature', 'Day_Average', 'sin(year)', 'cos(year)', 'sin(6mo)', 'cos(6mo)', 'sin(day)', 'cos(day)']] )\n",
    "\n",
    "(test['Goal'] - test['Predicted_Value']).plot()\n",
    "print sklearn.metrics.mean_squared_error(test['Goal'], test['Predicted_Value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cut_year = 2012\n",
    "\n",
    "train = temps_df[ temps_df.index.year < cut_year ].dropna(how='any')\n",
    "test  = temps_df[ temps_df.index.year >= cut_year].dropna(how='any')\n",
    "\n",
    "regress = sklearn.linear_model.LinearRegression().fit( \n",
    "        X=train[['Temperature', 'Day_Average', 'sin(year)', 'cos(year)', 'sin(day)', 'cos(day)']], \n",
    "        y=train['Goal'])\n",
    "\n",
    "test['Predicted_Value'] = regress.predict(X=test[['Temperature', 'Day_Average', 'sin(year)', 'cos(year)', 'sin(day)', 'cos(day)']])\n",
    "\n",
    "test[['Goal', 'Predicted_Value']].plot()\n",
    "print sklearn.metrics.mean_squared_error(test['Goal'], test['Predicted_Value'])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exit Tickets\n",
    "1. Describe how you would cross-validate a time series model.\n",
    "1. Describe the difference between autoregressive and moving average terms in an ARMA model.\n",
    "1. Explain an FFT to a layman."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Copyright &copy; 2015 The Data Incubator.  All rights reserved.*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
