{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{u'city': u'De Forest', u'review_count': 26, u'name': u'Pine Cone Restaurant', u'neighborhoods': [], u'type': u'business', u'business_id': u'JwUE5GmEO-sH1FuwJgKBlQ', u'full_address': u'6162 US Highway 51\\nDe Forest, WI 53532', u'hours': {}, u'state': u'WI', u'longitude': -89.335844, u'stars': 4.0, u'latitude': 43.238893, u'attributes': {u'Take-out': True, u'Price Range': 1, u'Outdoor Seating': False, u'Caters': False, u'Noise Level': u'average', u'Parking': {u'garage': False, u'street': False, u'validated': False, u'lot': True, u'valet': False}, u'Delivery': False, u'Attire': u'casual', u'Has TV': True, u'Good For': {u'dessert': False, u'latenight': False, u'lunch': True, u'dinner': False, u'brunch': False, u'breakfast': False}, u'Takes Reservations': False, u'Ambience': {u'romantic': False, u'intimate': False, u'touristy': False, u'hipster': False, u'divey': False, u'classy': False, u'trendy': False, u'upscale': False, u'casual': False}, u'Waiter Service': True, u'Accepts Credit Cards': True, u'Good for Kids': True, u'Good For Groups': True, u'Alcohol': u'none'}, u'open': True, u'categories': [u'Restaurants']}]\n"
     ]
    }
   ],
   "source": [
    "# Author: Selma Gomez Orr <selmagomezorrds@gmail.com> January 30, 2016\n",
    "\n",
    "##########################################################################\n",
    "## Imports\n",
    "##########################################################################\n",
    "\n",
    "import requests, urllib2, gzip, urllib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import ujson\n",
    "import dill\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "##########################################################################\n",
    "## Constants\n",
    "##########################################################################\n",
    "\n",
    "url = \"http://thedataincubator.s3.amazonaws.com/coursedata/mldata/yelp_train_academic_dataset_review.json.gz\"\n",
    "\n",
    "url2 = \"http://thedataincubator.s3.amazonaws.com/coursedata/mldata/yelp_train_academic_dataset_business.json.gz\"\n",
    "\n",
    "##########################################################################\n",
    "## Program - Miniproject: nlp Bag of Words\n",
    "##########################################################################\n",
    "\n",
    "\n",
    "#Download reviews file\n",
    "urllib.urlretrieve(url,'Reviews')\n",
    "\n",
    "reviews_list = []\n",
    "with gzip.open('Reviews', 'rb') as f:\n",
    "    for line in f.readlines():\n",
    "        review = ujson.loads(line)\n",
    "        reviews_list.append(review)\n",
    "        \n",
    "#print reviews_list[0:2]\n",
    "\n",
    "#Download all companies file fromw which only restaurants will be extracted.\n",
    "urllib.urlretrieve(url2, \"Restaurants\")\n",
    "        \n",
    "restaurants_list = []\n",
    "with gzip.open('Restaurants', 'rb') as f:\n",
    "    for line in f:\n",
    "        restaurant = ujson.loads(line)\n",
    "        if 'Restaurants' in restaurant['categories']:\n",
    "            restaurants_list.append(restaurant)\n",
    "\n",
    "\n",
    "print restaurants_list[0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>business_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dr. goldberg offers everything i look for in a...</td>\n",
       "      <td>vcNAWiLM4dR7D2nwwJ7nCA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Unfortunately, the frustration of being Dr. Go...</td>\n",
       "      <td>vcNAWiLM4dR7D2nwwJ7nCA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dr. Goldberg has been my doctor for years and ...</td>\n",
       "      <td>vcNAWiLM4dR7D2nwwJ7nCA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Been going to Dr. Goldberg for over 10 years. ...</td>\n",
       "      <td>vcNAWiLM4dR7D2nwwJ7nCA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Got a letter in the mail last week that said D...</td>\n",
       "      <td>vcNAWiLM4dR7D2nwwJ7nCA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text             business_id\n",
       "0  dr. goldberg offers everything i look for in a...  vcNAWiLM4dR7D2nwwJ7nCA\n",
       "1  Unfortunately, the frustration of being Dr. Go...  vcNAWiLM4dR7D2nwwJ7nCA\n",
       "2  Dr. Goldberg has been my doctor for years and ...  vcNAWiLM4dR7D2nwwJ7nCA\n",
       "3  Been going to Dr. Goldberg for over 10 years. ...  vcNAWiLM4dR7D2nwwJ7nCA\n",
       "4  Got a letter in the mail last week that said D...  vcNAWiLM4dR7D2nwwJ7nCA"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create a dataframe with the text and business_id from the reviews for join.\n",
    "fields = ['text', 'business_id']\n",
    "\n",
    "df_reviews = pd.DataFrame(reviews_list, columns = fields)\n",
    "\n",
    "df_reviews.head()\n",
    "#df_reviews.describe()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>categories</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>JwUE5GmEO-sH1FuwJgKBlQ</td>\n",
       "      <td>[Restaurants]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>uGykseHzyS5xAMWoN6YUqA</td>\n",
       "      <td>[American (Traditional), Restaurants]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LRKJF43s9-3jG9Lgx4zODg</td>\n",
       "      <td>[Food, Ice Cream &amp; Frozen Yogurt, Fast Food, R...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RgDg-k9S5YD_BaxMckifkg</td>\n",
       "      <td>[Chinese, Restaurants]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>_wZTYYL7cutanzAnJUTGMA</td>\n",
       "      <td>[Bars, American (Traditional), Nightlife, Loun...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              business_id                                         categories\n",
       "0  JwUE5GmEO-sH1FuwJgKBlQ                                      [Restaurants]\n",
       "1  uGykseHzyS5xAMWoN6YUqA              [American (Traditional), Restaurants]\n",
       "2  LRKJF43s9-3jG9Lgx4zODg  [Food, Ice Cream & Frozen Yogurt, Fast Food, R...\n",
       "3  RgDg-k9S5YD_BaxMckifkg                             [Chinese, Restaurants]\n",
       "4  _wZTYYL7cutanzAnJUTGMA  [Bars, American (Traditional), Nightlife, Loun..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create a dataframe with the category and business_id from the business info for join.\n",
    "\n",
    "fields2 = ['business_id', 'categories']\n",
    "\n",
    "df_restaurants = pd.DataFrame(restaurants_list, columns = fields2)\n",
    "\n",
    "df_restaurants.head()\n",
    "#df_restaurants.describe() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>business_id</th>\n",
       "      <th>categories</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Good truck stop dining at the right price. We ...</td>\n",
       "      <td>JwUE5GmEO-sH1FuwJgKBlQ</td>\n",
       "      <td>[Restaurants]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>If you like lot lizards, you'll love the Pine ...</td>\n",
       "      <td>JwUE5GmEO-sH1FuwJgKBlQ</td>\n",
       "      <td>[Restaurants]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Enjoyable experience for the whole family. The...</td>\n",
       "      <td>JwUE5GmEO-sH1FuwJgKBlQ</td>\n",
       "      <td>[Restaurants]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>One of my favorite truck stop diners with soli...</td>\n",
       "      <td>JwUE5GmEO-sH1FuwJgKBlQ</td>\n",
       "      <td>[Restaurants]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Only went here once about a year and a half ag...</td>\n",
       "      <td>JwUE5GmEO-sH1FuwJgKBlQ</td>\n",
       "      <td>[Restaurants]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text             business_id  \\\n",
       "0  Good truck stop dining at the right price. We ...  JwUE5GmEO-sH1FuwJgKBlQ   \n",
       "1  If you like lot lizards, you'll love the Pine ...  JwUE5GmEO-sH1FuwJgKBlQ   \n",
       "2  Enjoyable experience for the whole family. The...  JwUE5GmEO-sH1FuwJgKBlQ   \n",
       "3  One of my favorite truck stop diners with soli...  JwUE5GmEO-sH1FuwJgKBlQ   \n",
       "4  Only went here once about a year and a half ag...  JwUE5GmEO-sH1FuwJgKBlQ   \n",
       "\n",
       "      categories  \n",
       "0  [Restaurants]  \n",
       "1  [Restaurants]  \n",
       "2  [Restaurants]  \n",
       "3  [Restaurants]  \n",
       "4  [Restaurants]  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Merge the reviews dataframe with the restaurants dataframe to get only reviews of restaurants.\n",
    "df_food = pd.merge(df_reviews, df_restaurants, on = 'business_id')\n",
    "\n",
    "df_food.head()\n",
    "#df_food.describe()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "574278\n",
      "[u\"If you like lot lizards, you'll love the Pine Cone!\"\n",
      " u'Enjoyable experience for the whole family. The wait staff was courteous and friendly; the food was reasonably priced and a good value. A word of advice--LEAVE ROOM FOR DESSERT! the deserters are great but huge! Plan to bring some home'\n",
      " u\"One of my favorite truck stop diners with solid food and friendly, quick service. My god, those desserts are huge! I can't imagine eating that giant cream puff. \\nAll the food we had was delicious and I love how they leave a carafe of coffee on the table. Love this place. Would definitely be back if I was in the area!\"\n",
      " u\"Only went here once about a year and a half ago, but they had great pancakes! My only problem with it at the time was that they allowed smoking, so I left smelling like a cigarette. With the change in law, I'm sure the atmosphere has improved!\"]\n"
     ]
    }
   ],
   "source": [
    "#Select out the text for those reviews determined to be from restauarnts.\n",
    "\n",
    "text = np.array(df_food['text'])\n",
    "\n",
    "print len(text)\n",
    "print text [1:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(574278, 173613)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create the vectors for single words.\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "vec1 = CountVectorizer(stop_words=nltk.corpus.stopwords.words('english'))\n",
    "vec1_mat = vec1.fit_transform(text)\n",
    "vec1_mat.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(574278, 7811592)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create the vector for the word-pairs.\n",
    "vec2 = CountVectorizer(ngram_range= (2,2), stop_words=nltk.corpus.stopwords.words('english'))\n",
    "vec2_mat = vec2.fit_transform(text)\n",
    "vec2_mat.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Store instance of the matrices using dill.\n",
    "\n",
    "with open('vec1_file','w') as f:\n",
    "    dill.dump(vec1_mat,f)\n",
    "    \n",
    "with open('vec2_file', 'w') as f:\n",
    "    dill.dump(vec2_mat, f)\n",
    "    \n",
    "with open('vec1_ojb_file', 'w') as f:\n",
    "    dill.dump(vec1, f)\n",
    "    \n",
    "with open('vec2_obj_file', 'w') as f:\n",
    "    dill.dump(vec2, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(574278, 173613)\n",
      "(574278, 7811592)\n"
     ]
    }
   ],
   "source": [
    "import dill \n",
    "\n",
    "#Load the instance of the matrices using dill.\n",
    "vec1_mat = dill.load(open('vec1_file', 'r'))\n",
    "vec2_mat = dill.load(open('vec2_file', 'r'))\n",
    "vec1 = dill.load(open('vec1_ojb_file', 'r'))\n",
    "vec2 = dill.load(open('vec2_obj_file', 'r'))\n",
    "\n",
    "#Check shape.\n",
    "print vec1_mat.shape\n",
    "print vec2_mat.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37171596\n",
      "36597378\n"
     ]
    }
   ],
   "source": [
    "from scipy.sparse import *\n",
    "\n",
    "#Get total count of all words for each matrix.\n",
    "total1 = csr_matrix.sum(vec1_mat)\n",
    "total2 = csr_matrix.sum(vec2_mat)\n",
    "\n",
    "print total1\n",
    "print total2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "173613\n",
      "7811592\n",
      "[623   1   1   1]\n",
      "[1 1 1 8]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Get total count for each word or pair of words.\n",
    "count1 = np.array(csr_matrix.sum(vec1_mat, 0)[0])[0]\n",
    "count2 = np.array(csr_matrix.sum(vec2_mat, 0)[0])[0]\n",
    "\n",
    "print len(count1)\n",
    "print len(count2)\n",
    "print count1[1:5]\n",
    "print count2[1:5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "173613\n",
      "7811592\n",
      "[u'000', u'0000', u'000000', u'0000000']\n",
      "[u'00 000', u'00 00am', u'00 00p', u'00 00pm']\n"
     ]
    }
   ],
   "source": [
    "#Get the vocabularies for each vector\n",
    "vocab1 = vec1.get_feature_names()\n",
    "vocab2 = vec2.get_feature_names()\n",
    "\n",
    "print len(vocab1)\n",
    "print len(vocab2)\n",
    "print vocab1[1:5]\n",
    "print vocab2[1:5]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "173613\n",
      "7811592\n",
      "[(u'000', 623), (u'0000', 1), (u'000000', 1), (u'0000000', 1)]\n",
      "[(u'00 000', 1), (u'00 00am', 1), (u'00 00p', 1), (u'00 00pm', 8)]\n"
     ]
    }
   ],
   "source": [
    "#Create a list of tuples of the word or word-pair and the count\n",
    "data1 = zip(vocab1, count1)\n",
    "data2 = zip(vocab2, count2)\n",
    "\n",
    "print len(data1)\n",
    "print len(data2)\n",
    "\n",
    "print data1[1:5]\n",
    "print data2[1:5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Create a dictionary with probabilities.\n",
    "\n",
    "prob1_dict = {}\n",
    "for item in data1:\n",
    "    prob1_dict[item[0]] = item[1]/float(total1)\n",
    "\n",
    "prob2_dict ={}\n",
    "for elem in data2:\n",
    "    prob2_dict[elem[0]] = elem[1]/float(total2)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7811592\n",
      "[(346.73015346408044, [u'babystack cafe']), (0.088804332115599183, [u'soggy said']), (0.29196273479680451, [u'service deliciousness']), (4.646536946397064, [u'siracha enjoy'])]\n"
     ]
    }
   ],
   "source": [
    "#Create a dictionary with the calculations.\n",
    "alpha = 2.*10**-19\n",
    "calc_list = []\n",
    "\n",
    "for entry in prob2_dict:\n",
    "    pair = entry.split()\n",
    "    p1 = pair[0]\n",
    "    p2 = pair[1]\n",
    "    food_gram = p1+\" \"+p2\n",
    "    calc = (prob2_dict[entry] + alpha)/((prob1_dict[p1] *prob1_dict[p2]) + (alpha*total1))\n",
    "    calc_list.append((calc, [food_gram]))\n",
    "\n",
    "print len(calc_list)\n",
    "\n",
    "print calc_list[1:5]\n",
    "\n",
    "\n",
    "                                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "final_list = sorted(calc_list)\n",
    "top = final_list[-100:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[u'upward projects'], [u'homer simpson'], [u'ama ebi'], [u'salo salo'], [u'hob nobs'], [u'turo turo'], [u'tsk tsk'], [u'fritto misto'], [u'demi glace'], [u'bla bla'], [u'highs lows'], [u'hon machi'], [u'val vista'], [u'goi cuon'], [u'bai thong'], [u'2weqs rnoobhb1kshkyosq'], [u'fra diavolo'], [u'harry potter'], [u'artery clogging'], [u'bells whistles'], [u'sais quoi'], [u'cullen skink'], [u'jap chae'], [u'itsy bitsy'], [u'betty boop'], [u'rx boiler'], [u'chino bandido'], [u'womp womp'], [u'ghillie dhu'], [u'shiner bock'], [u'yada yada'], [u'valle luna'], [u'yadda yadda'], [u'woonam jung'], [u'mccormick schmick'], [u'rustler rooste'], [u'sous vide'], [u'malai kofta'], [u'porta alba'], [u'ritz carlton'], [u'wal mart'], [u'aguas frescas'], [u'dueling pianos'], [u'kao tod'], [u'mille feuille'], [u'perrier jouet'], [u'khao soi'], [u'bradley ogden'], [u'ak yelpcdn'], [u'barnes noble'], [u'patatas bravas'], [u'lomo saltado'], [u'haricot vert'], [u'luc lac'], [u'bandeja paisa'], [u'dol sot'], [u'celine dion'], [u'chicha morada'], [u'puerto rican'], [u'pel meni'], [u'nuoc mam'], [u'deja vu'], [u'laan xang'], [u'innis gunn'], [u'holyrood 9a'], [u'nanay gloria'], [u'lloyd wright'], [u'vice versa'], [u'krispy kreme'], [u'pura vida'], [u'molecular gastronomy'], [u'grana padano'], [u'uuu uuu'], [u'nooks crannies'], [u'marche bacchus'], [u'dac biet'], [u'alain ducasse'], [u'hors oeuvres'], [u'leaps bounds'], [u'feng shui'], [u'rula bula'], [u'f_5_unx wrafcxuakbzrdw'], [u'tammie coe'], [u'ore ida'], [u'roka akor'], [u'hu tieu'], [u'ropa vieja'], [u'gulab jamun'], [u'riff raff'], [u'tutti santi'], [u'himal chuli'], [u'hoity toity'], [u'hodge podge'], [u'baskin robbins'], [u'khai hoan'], [u'reina pepiada'], [u'cien agaves'], [u'itty bitty'], [u'knick knacks'], [u'ezzyujdouig4p gyb3pv_a']]\n"
     ]
    }
   ],
   "source": [
    "bigrams_list = []\n",
    "for gram in top:\n",
    "    bigrams_list.append(gram[1])\n",
    "\n",
    "print bigrams_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
